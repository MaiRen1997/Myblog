Subtitle	Machine Translation
I want to tell you a story	我想给大家讲一个
about artificial intelligence and farmers.	关于人工智能和农民的故事。
Now, what a strange combination, right?	现在，这是多么奇怪的组合，对吧？
Two topics could not sound more different from each other.	"两个主题听起来
截然不同。"
But did you know that modern farming actually involves a lot of technology?	"但你知道现代农业
实际上涉及很多技术吗？"
So computer vision is used to predict crop yields.	"因此计算机视觉被用来
预测农作物产量。"
And artificial intelligence is used to find,	"人工智能
用于发现、"
identify and get rid of insects.	识别和消灭昆虫。
Predictive analytics helps figure out extreme weather conditions	"预测分析有助于找出
"
like drought or hurricanes.	干旱或飓风等极端天气条件。
But this technology is also alienating to farmers.	"但这项技术
也让农民感到陌生。"
And this all came to a head in 2017	2017 年，
with the tractor company John Deere when they introduced smart tractors.	"拖拉机公司约翰迪尔 (John Deere)
推出了智能拖拉机，这一切都达到了顶峰。"
So before then, if a farmer's tractor broke,	"所以在此之前，
如果农民的拖拉机坏了，"
they could just repair it themselves or take it to a mechanic.	"他们只能自己修理
或交给机械师。"
Well, the company actually made it illegal	嗯，该公司实际上将
for farmers to fix their own equipment.	农民自己修理设备定为非法。
You had to use a licensed technician	你必须使用有执照的技术人员，
and farmers would have to wait for weeks	农民们必须等待数周，
while their crops rot and pests took over.	直到他们的农作物腐烂和害虫蔓延。
So they took matters into their own hands.	所以他们把事情掌握在自己手中。
Some of them learned to program,	他们中的一些人学会了编程，
and they worked with hackers to create patches to repair their own systems.	"并与黑客合作创建
补丁来修复自己的系统。"
In 2022,	2022 年，在世界上
at one of the largest hacker conferences in the world, DEFCON,	"最大的黑客
会议之一 DEFCON 上，"
a hacker named Sick Codes and his team	一位名叫 Sick Codes 的黑客和他的团队向
showed everybody how to break into a John Deere tractor,	"所有人展示了如何闯
入约翰迪尔拖拉机，这"
showing that, first of all, the technology was vulnerable,	"表明，首先，
该技术是脆弱的，"
but also that you can and should own your own equipment.	"但也表明 您可以而且应该
拥有自己的设备。"
To be clear, this is illegal,	需要明确的是，这是非法的，
but there are people trying to change that.	"但有人
试图改变这一点。"
Now that movement is called the “right to repair.”	"现在，这项运动被称为
“修复权”。"
The right to repair goes something like this.	"修理权
是这样的。"
If you own a piece of technology,	如果你拥有一项技术，
it could be a tractor, a smart toothbrush,	它可能是拖拉机、智能牙刷、
a washing machine,	洗衣机，
you should have the right to repair it if it breaks.	"
如果它坏了，你应该有权修理它。"
So why am I telling you this story?	那么我为什么要告诉你这个故事呢？
The right to repair needs to extend to artificial intelligence.	"修复权需要延伸
至人工智能。"
Now it seems like every week	现在，人工智能领域似乎每周都会出现
there is a new and mind-blowing innovation in AI.	"令人兴奋的新
创新。"
But did you know that public confidence is actually declining?	"但你知道公众信心
实际上正在下降吗？"
A recent Pew poll showed that more Americans are concerned	"皮尤研究中心最近的一项民意调查显示，对这项技术感到
担忧的美国人"
than they are excited about the technology.	"多于兴奋的美国人
。"
This is echoed throughout the world.	这在世界各地得到回应。
The World Risk Poll shows	世界风险民意调查显示，
that respondents from Central and South America and Africa	"来自
中南美洲和非洲的受访"
all said that they felt AI would lead to more harm than good for their people.	"者均表示，他们认为人工智能会给
他们的人民带来弊大于利。"
As a social scientist and an AI developer,	作为一名社会科学家和人工智能开发人员，
this frustrates me.	这让我感到沮丧。
I'm a tech optimist	我是一名技术乐观主义者，
because I truly believe this technology can lead to good.	"因为我坚信
这项技术可以带来好处。"
So what's the disconnect?	那么脱节是什么？
Well, I've talked to hundreds of people over the last few years.	"嗯，过去几年我已经和数百人交谈过
。"
Architects and scientists, journalists and photographers,	"建筑师和科学家、
记者和摄影师、"
ride-share drivers and doctors,	拼车司机和医生，
and they all say the same thing.	他们都说同样的话。
People feel like an afterthought.	人们感觉像是事后诸葛亮。
They all know that their data is harvested often without their permission	"他们都知道，他们的数据
经常在未经他们许可的情况下被收集来"
to create these sophisticated systems.	创建这些复杂的系统。
They know that these systems are determining their life opportunities.	"他们知道这些系统
正在决定他们的生活机会。"
They also know that nobody ever bothered to ask them	"他们还知道，没有人
费心去问他们"
how the system should be built,	应该如何构建系统，
and they certainly have no idea where to go if something goes wrong.	"而且他们当然不知道
如果出现问题该去哪里。"
We may not own AI systems,	我们可能不拥有人工智能系统，
but they are slowly dominating our lives.	但它们正在慢慢主宰我们的生活。
We need a better feedback loop	我们需要在
between the people who are making these systems,	"
制造这些系统的人和"
and the people who are best determined to tell us	"最有
决心告诉我们"
how these AI systems should interact in their world.	"这些人工智能系统
应该如何在他们的世界中互动的人之间建立更好的反馈循环。"
One step towards this is a process called red teaming.	"实现这一目标的一个步骤
是称为红队的过程。"
Now, red teaming is a practice that was started in the military,	"现在，红队是一种
从军队开始的做法，"
and it's used in cybersecurity.	并用于网络安全。
In a traditional red-teaming exercise,	在传统的红队演习中，
external experts are brought in to break into a system,	"外部专家被请来
闯入系统，"
sort of like what Sick Codes did with tractors, but legal.	"有点像 Sick Codes
对拖拉机所做的那样，但合法。"
So red teaming acts as a way of testing your defenses	"因此，红队是
测试你的防御能力的一种方式"
and when you can figure out where something will go wrong,	"，当你能找出
哪里出了问题时，"
you can figure out how to fix it.	你就能找出解决方法。
But when AI systems go rogue,	但当人工智能系统失控时，
it's more than just a hacker breaking in.	这不仅仅是黑客闯入的问题。
The model could malfunction or misrepresent reality.	"该模型可能会发生故障
或歪曲现实。"
So, for example, not too long ago,	例如，不久前，
we saw an AI system attempting diversity	我们看到一个人工智能系统
by showing historically inaccurate photos.	通过显示历史上不准确的照片来尝试多样性。
Anybody with a basic understanding of Western history	"任何对
西方历史有基本了解的人"
could have told you that neither the Founding Fathers	"都会告诉你
，开国元勋"
nor Nazi-era soldiers would have been Black.	"和纳粹时代的士兵
都不会是黑人。 那么"
In that case, who qualifies as an expert?	，谁有资格成为专家呢？
You.	你。
I'm working with thousands of people all around the world	"我正在与世界各地的数千人合作进行
"
on large and small red-teaming exercises,	大大小小的红队练习，
and through them we found and fixed mistakes in AI models.	"通过他们我们发现
并修复了人工智能模型中的错误。"
We also work with some of the biggest tech companies in the world:	"我们还与世界上一些最大的
科技公司合作："
OpenAI, Meta, Anthropic, Google.	OpenAI、Meta、Anthropic、Google。
And through this, we've made models work better for more people.	"通过这一点，我们让模型
更好地为更多人服务。"
Here's a bit of what we've learned.	这是我们学到的一些内容。
We partnered with the Royal Society in London to do a scientific,	"我们与伦敦皇家学会合作，与疾病科学家一起
举办了一场科学、"
mis- and disinformation event with disease scientists.	"错误和虚假信息活动
。"
What these scientists found	这些科学家发现，
is that AI models actually had a lot of protections	"人工智能模型实际上
"
against COVID misinformation.	对新冠错误信息有很多保护措施。
But for other diseases like measles, mumps and the flu,	"但对于麻疹、
腮腺炎和流感等其他疾病，"
the same protections didn't apply.	同样的保护措施并不适用。
We reported these changes,	我们报告了这些变化，
they’re fixed and now we are all better protected	"它们已得到修复，现在
我们都得到了更好的保护，"
against scientific mis- and disinformation.	"免受科学错误
和虚假信息的侵害。"
We did a really similar exercise with architects at Autodesk University,	"我们与欧特克大学的建筑师进行了非常类似的练习
，"
and we asked them a simple question:	我们问他们一个简单的问题：
Will AI put them out of a job?	人工智能会让他们失业吗？
Or more specifically,	或者更具体地说，
could they imagine a modern AI system	他们能否想象一个
that would be able to design the specs of a modern art museum?	"能够设计
现代艺术博物馆规格的现代人工智能系统？"
The answer, resoundingly, was no.	答案是否定的。
Here's why, architects do more than just draw buildings.	"这就是为什么建筑师所做的
不仅仅是绘制建筑物。"
They have to understand physics and material science.	"他们必须了解物理学
和材料科学。"
They have to know building codes,	他们必须了解建筑规范，
and they have to do that	并且必须在
while making something that evokes emotion.	"制作能够
唤起情感的东西的同时做到这一点。"
What the architects wanted was an AI system	"建筑师想要的
是一个能够"
that interacted with them, that would give them feedback,	"与他们交互的人工智能系统，
可以给他们反馈，"
maybe proactively offer design recommendations.	"也许可以主动提供
设计建议。"
And today's AI systems, not quite there yet.	"而今天的人工智能系统
还没有完全实现。"
But those are technical problems.	但这些都是技术问题。
People building AI are incredibly smart,	构建人工智能的人非常聪明，
and maybe they could solve all that in a few years.	"也许他们可以
在几年内解决所有问题。"
But that wasn't their biggest concern.	但这并不是他们最关心的问题。
Their biggest concern was trust.	他们最关心的是信任。
Now architects are liable if something goes wrong with their buildings.	"现在，如果
他们的建筑出现问题，建筑师就要承担责任。"
They could lose their license,	他们可能会被吊销驾照，
they could be fined, they could even go to prison.	"可能会被罚款，甚至
可能会入狱。"
And failures can happen in a million different ways.	"失败可能
以一百万种不同的方式发生。"
For example, exit doors that open the wrong way,	"例如，出口门
打开方向错误，"
leading to people being crushed in an evacuation crisis,	"导致人们
在疏散危机中被压伤，"
or broken glass raining down onto pedestrians in the street	"或者
"
because the wind blows too hard and shatters windows.	"由于风吹得太猛，
窗户被吹碎，碎玻璃如雨点般落到街上的行人身上。"
So why would an architect trust an AI system with their job,	"那么，如果建筑师在发现错误时无法介入并修复错误，为什么他们会信任
人工智能系统来完成他们的工作和"
with their literal freedom,	真正的自由呢
if they couldn't go in and fix a mistake if they found it?	"
？"
So we need to figure out these problems today, and I'll tell you why.	"所以我们今天需要弄清楚这些问题
，我会告诉你原因。"
The next wave of artificial intelligence systems, called agentic AI,	"下一波人工智能
系统被称为代理人工智能，它"
is a true tipping point	是
between whether or not we retain human agency,	"
我们是否保留人类代理"
or whether or not AI systems make our decisions for us.	"或人工智能系统是否
为我们做出决定之间的真正转折点。"
Imagine an AI agent as kind of like a personal assistant.	"想象一下人工智能代理有点
像私人助理。"
So, for example, a medical agent might determine	"例如，
医疗代理人可能会确定"
whether or not your family needs doctor's appointments,	"您的家人是否需要
预约医生，"
it might refill prescription medications, or in case of an emergency,	"可能会补充处方药，
或者在紧急情况下将"
send medical records to the hospital.	医疗记录发送到医院。
But AI agents can't and won't exist	但
unless we have a true right to repair.	除非我们拥有真正的修复权，否则人工智能代理不能也不可能存在。 除非你能进行一些基本的诊断，否则
What parent would trust their child's health to an AI system	"哪个父母会把
孩子的健康托付给人工智能系统呢"
unless you could run some basic diagnostics?	"
？ 除非你能像初级员工那样重新培训它，否则"
What professional would trust an AI system with job decisions,	"哪个专业人士会信任
人工智能系统来做出工作决策呢"
unless you could retrain it the way you might a junior employee?	"
？"
Now, a right to repair might look something like this.	"现在，修复权
可能看起来像这样。"
You could have a diagnostics board	您可以有一个诊断板，
where you run basic tests that you design,	您可以在其中运行您设计的基本测试，
and if something's wrong, you could report it to the company	"如果出现问题，
您可以向公司报告"
and hear back when it's fixed.	并在修复后收到回复。
Or you could work with third parties like ethical hackers	"或者您可以与第三方合作，
例如道德黑客，"
who make patches for systems like we do today.	"他们像我们今天一样为系统制作补丁
。"
You can download them and use them to improve your system	"您可以下载它们并使用它们
"
the way you want it to be improved.	按照您希望的方式改进您的系统。
Or you could be like these intrepid farmers and learn to program	"或者您可以像这些勇敢的
农民一样，学习编程"
and fine-tune your own systems.	和微调自己的系统。
We won't achieve the promised benefits of artificial intelligence	-
unless we figure out how to bring people into the development process.	"除非我们弄清楚如何让人们
参与开发过程，否则我们无法实现人工智能所承诺的好处。"
I've dedicated my career to responsible AI,	"我将我的职业生涯奉献
给了负责任的人工智能，"
and in that field we ask the question,	在这个领域我们提出这样的问题：
what can companies build to ensure that people trust AI?	"公司可以构建什么
来确保人们信任人工智能？"
Now, through these red-teaming exercises, and by talking to you,	"现在，通过这些红队练习
以及与您的交谈，"
I've come to realize that we've been asking the wrong question all along.	"我逐渐意识到我们一直在
问错误的问题。"
What we should have been asking is what tools can we build	"我们应该问的
是，我们可以构建哪些工具，"
so people can make AI beneficial for them?	以便人们可以让人工智能为他们带来好处？
Technologists can't do it alone.	技术人员无法单独做到这一点。
We can only do it with you.	我们只能和你一起做。
Thank you.	谢谢。
(Applause)	（掌声）