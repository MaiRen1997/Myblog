(window.webpackJsonp=window.webpackJsonp||[]).push([[416],{907:function(n,e,t){"use strict";t.r(e);var o=t(7),a=Object(o.a)({},(function(){var n=this,e=n._self._c;return e("ContentSlotsDistributor",{attrs:{"slot-key":n.$parent.slotKey}},[e("p",[n._v("This is something you won't like.\nBut here everyone is a "),e("strong",[n._v("liar")]),n._v(".\n"),e("strong",[n._v("Don't take it too personally")]),n._v(".\n"),e("strong",[n._v("What I mean is that")]),n._v(" lying is very common and it is now well-established that we lie on a daily basis.\n"),e("strong",[n._v("Indeed")]),n._v(", scientists have "),e("strong",[n._v("estimated")]),n._v(" that we "),e("strong",[n._v("tell around two lies per day")]),n._v(",\nalthough, of course, it's not that easy to establish those numbers with certainty.\nAnd, well, I introduce myself.\nI'm Riccardo, I'm a "),e("strong",[n._v("psychologist")]),n._v(" and a PhD candidate,\nand for my research project I study "),e("strong",[n._v("how good are people at detecting lies")]),n._v(".\nSeems cool, right? But I'm not joking.\nAnd you might wonder why a psychologist was then invited to give a TED Talk about AI.\nAnd well, I'm here today because I'm about to tell you how AI could be used to detect lies.\nAnd you will be very surprised by the answer.\nBut first of all, when is it relevant to detect lies?\nA first clear example that comes to my mind\nis in the "),e("strong",[n._v("criminal")]),n._v(" "),e("strong",[n._v("investigation")]),n._v(" "),e("strong",[n._v("field")]),n._v(".\nImagine you are a police officer and you want to "),e("strong",[n._v("interview")]),n._v(" a "),e("strong",[n._v("suspect")]),n._v(".\nAnd the suspect is "),e("strong",[n._v("providing some information to you")]),n._v(".\nAnd this information is actually leading to the next steps of the "),e("strong",[n._v("investigation")]),n._v(".\nWe certainly want to understand if the suspect is reliable or if they are trying to deceive us.\nThen another example comes to my mind,\nand I think this really affects all of us.\nSo please raise your hands\nif you would like to know if your partner "),e("strong",[n._v("cheated on")]),n._v(" you.")]),n._v(" "),e("p",[n._v("cheat on sb 强调的是欺骗了谁")]),n._v(" "),e("p",[n._v("cheat with sb 强调的联合谁，欺骗了某人")]),n._v(" "),e("p",[n._v("(Laughter)\nAnd don't be shy because I know.\n(Laughter)\nYeah. You see?\nIt's very relevant.\nHowever, "),e("strong",[n._v("I have to  say that we as humans are very bad at detecting lies")]),n._v(".\nIn fact, many studies have already confirmed that when people are asked to judge\nif someone is lying or not\nwithout knowing much about that person or the context,\npeople's accuracy is no better than the chance level,\nabout the same as flipping a coin.\nYou might also wonder\nif experts, such as police officers, "),e("strong",[n._v("prosecutors")]),n._v(", experts\nand even psychologists\nare better at detecting lies.\nAnd the answer is complex,\nbecause experience alone doesn't seem to be enough\nto help detect lies accurately.\nIt might help, but it's not enough.\nTo give you some numbers.\nIn a well-known "),e("strong",[n._v("meta-analysis")]),n._v(" that previous "),e("strong",[n._v("scholars")]),n._v(" did in 2006,\nthey found that "),e("strong",[n._v("naive")]),n._v(" judges' accuracy\nwas on average around 54 percent.\nExperts perform only slightly better,\nwith an accuracy rate around 55 percent.\n(Laughter)\nNot that impressive, right?\nAnd ...\nThose numbers actually come from the analysis\nof the results of 108 studies,\nmeaning that these findings are quite "),e("strong",[n._v("robust")]),n._v(".\nAnd of course, the debate is also much more "),e("strong",[n._v("complicated")]),n._v(" than this\nand also more nuanced.")]),n._v(" "),e("p",[e("strong",[n._v("complicated")]),n._v(" vs "),e("strong",[n._v("complex")])]),n._v(" "),e("p",[n._v('如果强调繁琐或难以处理，用 "more complicated"；')]),n._v(" "),e("p",[n._v('如果强调结构或内在关系复杂，用 "more complex"')]),n._v(" "),e("p",[n._v("But here the main "),e("strong",[n._v("take-home")]),n._v(" message\nis that humans are not good at detecting lies.")]),n._v(" "),e("p",[n._v('take-home message" 强调这是听众或读者应该“带回家”（即记住并理解）的核心观点。')]),n._v(" "),e("p",[e("strong",[n._v("What if we are creating an AI tool")]),n._v(" "),e("strong",[n._v("where everyone can detect if someone else is lying?")]),n._v("\nThis is not possible yet, so please don't "),e("strong",[n._v("panic")]),n._v(".\n(Laughter)\nBut this is what we tried to do in a recent study\nthat I did together with my "),e("strong",[n._v("brilliant")]),n._v(" colleagues\nwhom I need to thank.\nAnd actually, to let you understand what we did in our study,\nI need to first introduce you to some technical concepts\nand to the main "),e("strong",[n._v("characters")]),n._v(" of this story:\nLarge language models.\nLarge language models are AI systems\ndesigned to generate outputs in natural language\n"),e("strong",[n._v("in a way")]),n._v(" that almost "),e("strong",[n._v("mimics")]),n._v(" human communication.\nIf you are wondering how we teach these AI systems to detect lies,\nhere is where something called "),e("strong",[n._v("fine-tuning")]),n._v(" "),e("strong",[n._v("comes in")]),n._v(".\nBut let's use a "),e("strong",[n._v("metaphor")]),n._v(".\nImagine large language models being as students\nwho have "),e("strong",[n._v("gone through")]),n._v(" years of school,\nlearning a little bit about everything,\nsuch as language, concepts, facts.\nBut when it's time for them to specialize,\nlike in law school or in medical school,\nthey need more focused training.\nFine-tuning is that extra education.\nAnd of course, large language models don't learn as humans do.\nBut this is just to give you the main idea.\nThen, as for training students, you need books, "),e("strong",[n._v("lectures")]),n._v(", examples,\nfor training large language models you need "),e("strong",[n._v("datasets")]),n._v(".\nAnd for our study we considered three datasets,\none about personal opinions,\none about past "),e("strong",[n._v("autobiographical")]),n._v(" memories\nand one about future "),e("strong",[n._v("intentions")]),n._v(".\nThese datasets were already available from previous studies\nand contained both "),e("strong",[n._v("truthful")]),n._v(" and "),e("strong",[n._v("deceptive")]),n._v(" statements.\nTypically, you collect these types of statements\nby asking "),e("strong",[n._v("participants")]),n._v(' to tell the truth or to lie about something.\nFor example, if I was a participant in the truthful condition,\nand the task was\n"tell me about your past holidays,"\nthen I will tell the researcher about my previous holidays in Vietnam,\nand here we have a '),e("strong",[n._v("slide")]),n._v(" to "),e("strong",[n._v("prove")]),n._v(" it.\nFor the deceptive condition\nthey will randomly pick some of you who have never been to Vietnam,\nand they will ask you to make up a story\nand "),e("strong",[n._v("convince")]),n._v(" someone else that you've really been to Vietnam.\nAnd this is how it typically works.\nAnd as in all university courses, you might know this,\nafter "),e("strong",[n._v("lectures")]),n._v(" you have exams.\nAnd "),e("strong",[n._v("likewise")]),n._v(" after training our AI models,\nwe would like to test them.\nAnd the procedure that we followed,\nthat is actually the typical one, is the following.\nSo we picked some statements randomly from each dataset\nand we "),e("strong",[n._v("took them apart")]),n._v(".\nSo the model never saw these statements during the training phase.\nAnd only after the training was completed,\nwe used them as a test, as the final exam.\nBut who was our student then?\nIn this case, it was a large language model\ndeveloped by Google\nand called FLAN-T5.\nFlanny, for friends.\nAnd now that we have all the pieces of the process together,\nwe can actually "),e("strong",[n._v("dig deep into")]),n._v(" our study.\nOur study was "),e("strong",[n._v("composed")]),n._v(" by three main "),e("strong",[n._v("experiments")]),n._v(".\nFor the first "),e("strong",[n._v("experiment")]),n._v(", we "),e("strong",[n._v("fine-tuned")]),n._v(" our model, our FLAN-T5,\non each single dataset "),e("strong",[n._v("separately")]),n._v(".\nFor the second experiment,\nwe fine-tuned our model on two pairs of datasets together,\nand we tested it on the third "),e("strong",[n._v("remaining")]),n._v(" one,\nand we used all three possible combinations.\nFor the last final experiment,\nwe fine-tuned the model on a new, larger training test set\nthat we "),e("strong",[n._v("obtained")]),n._v(" by combining all the three datasets together.\nThe results were quite interesting\nbecause what we found was that in the first experiment,\nFLAN-T5 achieved an accuracy range between 70 percent and 80 percent.\nHowever, in the second experiment,\nFLAN-T5 dropped its accuracy to almost 50 percent.\nAnd then, surprisingly, in the third experiment,\nFLAN-T5 rose back to almost 80 percent.\nBut what does this mean?\nWhat can we learn from these results?\nFrom experiment one and three\nwe learn that language models\ncan effectively classify statements as deceptive,\n"),e("strong",[n._v("outperforming")]),n._v(" human "),e("strong",[n._v("benchmarks")]),n._v("\nand "),e("strong",[n._v("aligning with")]),n._v(" previous machine learning\nand deep learning models\nthat previous studies trained on the same datasets.\nHowever, from the second experiment,\nwe see that language models "),e("strong",[n._v("struggle")]),n._v("\nin "),e("strong",[n._v("generalizing")]),n._v(" this knowledge, this learning across different contexts.\nAnd this is "),e("strong",[n._v("apparently")]),n._v(" because\nthere is no one single "),e("strong",[n._v("universal")]),n._v(" rule of "),e("strong",[n._v("deception")]),n._v("\nthat we can easily apply in every context,\nbut "),e("strong",[n._v("linguistic")]),n._v(" "),e("strong",[n._v("cues")]),n._v(" of deception are context-dependent.\nAnd from the third experiment,\nwe learned that actually language models\ncan "),e("strong",[n._v("generalize")]),n._v(" well "),e("strong",[n._v("across")]),n._v(" different contexts,\nif only they have "),e("u",[n._v("been "),e("strong",[n._v("previously")]),n._v(" exposed to examples")]),n._v("\nduring the training "),e("strong",[n._v("phase")]),n._v(".\nAnd I think this sounds as good news.\nBut while this means that language models can be effectively applied\nfor real-life applications in lie detection,\nmore "),e("strong",[n._v("replication")]),n._v(" is needed because a single study is never enough\nso that from tomorrow we can all have these AI systems on our smartphones,\nand start detecting other people's lies.\nBut as a scientist, I have a vivid imagination\nand I would like to dream big.\nAnd also I would like to "),e("strong",[n._v("bring you with me")]),n._v(" in this "),e("strong",[n._v("futuristic")]),n._v(" journey "),e("strong",[n._v("for a while")]),n._v(".\nSo please imagine with me living in a world\nwhere this lie detection technology is "),e("strong",[n._v("well-integrated")]),n._v(" in our life,\nmaking everything from "),e("strong",[n._v("national security")]),n._v(" to social media a little bit safer.\nAnd imagine having this AI system that could actually "),e("strong",[n._v("spot")]),n._v(" "),e("strong",[n._v("fake")]),n._v(" opinions.\nFrom tomorrow, we could say\nwhen a politician is actually saying one thing\nand truly believes something else.\n(Laughter)\nAnd what about the security board context\nwhere people are asked about their "),e("strong",[n._v("intentions")]),n._v(" and reasons\nfor why they are crossing borders or boarding planes.\nWell, with these systems,\nwe could actually spot malicious intentions\nbefore they even happen.\nAnd what about the "),e("strong",[n._v("recruiting")]),n._v(" process?\n(Laughter)\nWe heard about this already.\nBut actually, companies could "),e("strong",[n._v("employ")]),n._v(" this AI\nto distinguish those who are really "),e("strong",[n._v("passionate")]),n._v(" about the role\nfrom those who are just trying to say the right things to get the job.\nAnd finally, we have social media.\nScammers trying to deceive you or to "),e("strong",[n._v("steal")]),n._v(" your "),e("strong",[n._v("identity")]),n._v(".\n"),e("strong",[n._v("All gone")]),n._v(".\nAnd someone else may claim something about "),e("strong",[n._v("fake")]),n._v(" news,\nand well, perfectly, language model could automatically read the news,\nflag them as "),e("strong",[n._v("deceptive")]),n._v(" or "),e("strong",[n._v("fake")]),n._v(",\nand we could even provide users with a "),e("strong",[n._v("credibility")]),n._v(" score\nfor the information they read.\nIt sounds like a "),e("strong",[n._v("brilliant")]),n._v(" future, right?\n(Laughter)\nYes, but ...\n"),e("strong",[n._v("all great progress comes with risks")]),n._v(".\nAs much as I'm excited about this future,\nI think we need to be careful.\nIf we are not cautious, in my view,\nwe could end up in a world\nwhere people might just "),e("strong",[n._v("blindly")]),n._v(" believe AI outputs.\nAnd I'm afraid this means that people will just be more likely\nto "),e("strong",[n._v("accuse")]),n._v(" others of lying just because an AI says so.\nAnd I'm not the only one with this view\nbecause another study already "),e("strong",[n._v("proved")]),n._v(" it.\nIn addition, if we totally "),e("strong",[n._v("rely on")]),n._v(" this lie detection technology\nto say someone else is lying or not,\n"),e("strong",[n._v("we risk losing")]),n._v(" another important key value in society.\nWe lose trust.\nWe won't need to trust -people anymore,\nbecause what we will do is just ask an AI to double check for us.\nBut are we really willing to blindly believe AI\nand give up our "),e("strong",[n._v("critical")]),n._v(" thinking?\nI think that's the future we need to avoid.\nWith hope for the future is more "),e("strong",[n._v("interpretability")]),n._v(".\nAnd I'm about to tell you what I mean.\nSimilar to when we look at "),e("strong",[n._v("reviews")]),n._v(" online,\nand we can both look at the total number of stars at places,\nbut also we can look more in detail at the "),e("strong",[n._v("positive and negative reviews")]),n._v(",\nand try to understand what are the positive sides,\nbut also what might have gone wrong,\nto eventually create our own and personal idea\nif that is the place where we want to go,\nwhere we want to be.\n"),e("strong",[n._v("Likewise")]),n._v(", imagine a world where AI doesn't just offer conclusions,\nbut also provides clear and understandable explanations\nbehind its decisions.\nAnd I "),e("strong",[n._v("envision")]),n._v(" a future\nwhere this lie detection technology\nwouldn't just provide us with a simple "),e("strong",[n._v("judgment")]),n._v(",\nbut also with clear explanations for why it thinks someone else is lying.\n"),e("strong",[n._v("And I would like a future where")]),n._v(", yes,\nthis lie detection technology is "),e("strong",[n._v("integrated")]),n._v(" in our life,\nor also AI technology in "),e("strong",[n._v("general")]),n._v(",\nbut still, at the same time,\nwe are able to think critically\nand decide when we want to trust in AI judgment\nor when we want to question it.\nTo conclude,\nI think the future of using AI for lie detection\nis not just about technological advancement,\nbut about enhancing our understanding and "),e("strong",[n._v("fostering")]),n._v(" trust.\nIt's about developing tools that don't replace human judgment\nbut "),e("strong",[n._v("empower")]),n._v(" it,\nensuring that we remain at the "),e("strong",[n._v("helm")]),n._v(".\nDon't step into a future with blind reliance on technology.\nLet's commit to deep understanding and "),e("strong",[n._v("ethical")]),n._v(" use,\nand we'll "),e("strong",[n._v("pursue")]),n._v(" the truth.\n(Applause)\nThank you.")]),n._v(" "),e("h2",{attrs:{id:"machine-translation这是你不会喜欢的事情。但在这里每个人都是骗子。别太介意。我的意思是说谎非常常见-而且现在我们每天都在说谎-这已是众所周知的事实。-事实上-科学家估计我们每天大约会说两次谎-尽管当然-要确定这些数字并不容易。-好吧-我来介绍一下自己。-我是里卡多-一名心理学家和博士生-我的研究项目是研究人们识别谎言的能力。-看起来很酷-对吧-但我不是在开玩笑。-你也许想知道为什么一位心理学家会被邀请-来做有关人工智能的-ted-演讲。我今天来这里是-为了告诉你们如何使用人工智能来检测谎言。-你一定会对答案感到非常惊讶。-但首先-什么时候检测谎言才是重要的-我想到-第一个明显的例子-就是刑事调查领域。-想象一下你是一名警察-你想要采访一名嫌疑人。-并且犯罪嫌疑人正在向你提供一些信息。-这些信息实际上引导了调查的下一步行动。-我们当然想了解嫌疑人是否可靠-或者他们是否试图欺骗我们。然后我想到另一个例子-我认为这确实影响到我们所有人。所以-如果你想知道你的伴侣是否欺骗了你-请举手。-笑声-别害羞-我知道。-笑声-是的。-你看-这非常有意义。-然而-我不得不说-我们人类-很不擅长识别谎言。-事实上-很多研究已经证实-当人们在对对方或具体情况不太了解的情况下-判断某人是否说谎时"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#machine-translation这是你不会喜欢的事情。但在这里每个人都是骗子。别太介意。我的意思是说谎非常常见-而且现在我们每天都在说谎-这已是众所周知的事实。-事实上-科学家估计我们每天大约会说两次谎-尽管当然-要确定这些数字并不容易。-好吧-我来介绍一下自己。-我是里卡多-一名心理学家和博士生-我的研究项目是研究人们识别谎言的能力。-看起来很酷-对吧-但我不是在开玩笑。-你也许想知道为什么一位心理学家会被邀请-来做有关人工智能的-ted-演讲。我今天来这里是-为了告诉你们如何使用人工智能来检测谎言。-你一定会对答案感到非常惊讶。-但首先-什么时候检测谎言才是重要的-我想到-第一个明显的例子-就是刑事调查领域。-想象一下你是一名警察-你想要采访一名嫌疑人。-并且犯罪嫌疑人正在向你提供一些信息。-这些信息实际上引导了调查的下一步行动。-我们当然想了解嫌疑人是否可靠-或者他们是否试图欺骗我们。然后我想到另一个例子-我认为这确实影响到我们所有人。所以-如果你想知道你的伴侣是否欺骗了你-请举手。-笑声-别害羞-我知道。-笑声-是的。-你看-这非常有意义。-然而-我不得不说-我们人类-很不擅长识别谎言。-事实上-很多研究已经证实-当人们在对对方或具体情况不太了解的情况下-判断某人是否说谎时"}},[n._v("#")]),n._v(' Machine Translation\n这是你不会喜欢的事情。\n但在这里每个人都是骗子。\n别太介意。\n我的意思是说谎非常常见，\n"而且现在\n我们每天都在说谎，这已是众所周知的事实。"\n"事实上，科学家估计\n我们每天大约会说两次谎，"\n"尽管当然，要\n确定这些数字并不容易。"\n好吧，我来介绍一下自己。\n"我是里卡多，一名心理学家\n和博士生，"\n"我的研究项目是研究\n人们识别谎言的能力。"\n看起来很酷，对吧？ 但我不是在开玩笑。\n"你也许想知道\n为什么一位心理学家会被邀请"\n来做有关人工智能的 TED 演讲。\n我今天来这里是\n"为了告诉你们\n如何使用人工智能来检测谎言。"\n"你一定会对答案感到非常惊讶\n。"\n"但首先，\n什么时候检测谎言才是重要的？ 我想到"\n"第一个明显的例子\n"\n就是刑事调查领域。\n"想象一下你是一名警察\n，你想要采访一名嫌疑人。"\n"并且犯罪嫌疑人正在\n向你提供一些信息。"\n"这些信息实际上引导了\n调查的下一步行动。"\n"我们当然想了解\n嫌疑人是否可靠，"\n或者他们是否试图欺骗我们。\n然后我想到另一个例子，\n我认为这确实影响到我们所有人。\n所以，\n"如果你想知道\n你的伴侣是否欺骗了你，请举手。"\n（笑声）\n别害羞，我知道。\n（笑声）\n是的。 你看？\n这非常有意义。\n"然而，我不得不说，\n我们人类"\n很不擅长识别谎言。\n"事实上，很多研究\n已经证实，"\n当人们在对对方或具体情况不太了解的情况下，判断\n某人是否说谎时，')]),n._v(" "),e("h2",{attrs:{id:"人们的准确率并不比偶然水平高-和-抛硬币差不多。您可能还想知道-警察、检察官、专家-甚至心理学家等专家是否更善于识别谎言。答案很复杂-因为单靠经验似乎-不足以准确地识别谎言。这或许有帮助-但还不够。给你一些数字。-在2006年-学者们所做的一项著名的荟萃分析中-他们发现天真的判断者的准确率平均约为54-。专家的表现仅略好一些-准确率约为-55-。-笑声-没什么特别的-对吧-而且-这些数字实际上来自对-108-项研究结果的分析-这-意味着这些发现非常可靠。-当然-争论要比这复杂得多-也更加微妙。但这里最主要的讯息-是-人类并不擅长察觉谎言。-如果我们创建一种人工智能工具-让-每个人都能检测出其他人是否在说谎-那会怎样-这目前还不可能-所以请不要惊慌。-笑声-但这正是我们在最近的研究中尝试做的-我和我的杰出的同事们一起做了这项研究-我需要向他们表示感谢。-实际上-为了让你了解我们在研究中所做的工作-我需要首先向你介绍一些技术概念-和这个故事的主角-大型语言模型。大型语言模型是-旨在以-几乎模仿人类交流的方式生成自然语言输出的人工智能系统。-如果你想知道我们如何教这些人工智能系统检测谎言-这就是所谓的微调。-但让我们打个比方。-想象一下大型语言模型就像-经过多年学校教育的学生-他们学习了各种知识-例如语言、概念、事实。但是当他们需要进入专业领域时-比如进入法学院或医学院-他们需要更有针对性的培训。微调就是额外的教育。-当然-大型语言模型的学习方式并不像人类那样。-但这只是为了告诉你主要思想。-然后-对于培训学生-你需要书籍、讲座、例子-对于训练大型语言模型-你需要数据集。-在我们的研究中-我们考虑了三个数据集-一个是关于个人观点-一个是关于过去的自传体记忆-一个是关于未来意图。-这些数据集已经从以前的研究中获得-包含真实的和欺骗性的陈述。-通常-你-通过要求参与者说实话或撒谎来收集这些类型的陈述。-例如-如果我是真实条件下的参与者-并且任务是-告诉我你过去的假期-那么我会告诉研究人员我以前在越南的假期-这里有一张幻灯片来证明这一点。为了欺骗对方-他们会随机挑选一些从未去过越南的人-要求你们编造一个故事-让别人相信你真的去过越南。-这就是它的典型工作方式。-你们可能知道-就像所有大学课程一样-上完课之后还要参加考试。同样-在训练我们的人工智能模型之后-我们也想对其进行测试。我们遵循的程序-实际上是典型的程序-如下所示。-因此-我们从每个数据集中随机挑选了一些语句-然后将它们分开。-因此模型在训练阶段从未见过这些陈述。-只有在培训完成后-我们才将它们用作测试-作为期末考试。但当时我们的学生是谁-在这种情况下-它是谷歌开发的一个大型语言模型"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#人们的准确率并不比偶然水平高-和-抛硬币差不多。您可能还想知道-警察、检察官、专家-甚至心理学家等专家是否更善于识别谎言。答案很复杂-因为单靠经验似乎-不足以准确地识别谎言。这或许有帮助-但还不够。给你一些数字。-在2006年-学者们所做的一项著名的荟萃分析中-他们发现天真的判断者的准确率平均约为54-。专家的表现仅略好一些-准确率约为-55-。-笑声-没什么特别的-对吧-而且-这些数字实际上来自对-108-项研究结果的分析-这-意味着这些发现非常可靠。-当然-争论要比这复杂得多-也更加微妙。但这里最主要的讯息-是-人类并不擅长察觉谎言。-如果我们创建一种人工智能工具-让-每个人都能检测出其他人是否在说谎-那会怎样-这目前还不可能-所以请不要惊慌。-笑声-但这正是我们在最近的研究中尝试做的-我和我的杰出的同事们一起做了这项研究-我需要向他们表示感谢。-实际上-为了让你了解我们在研究中所做的工作-我需要首先向你介绍一些技术概念-和这个故事的主角-大型语言模型。大型语言模型是-旨在以-几乎模仿人类交流的方式生成自然语言输出的人工智能系统。-如果你想知道我们如何教这些人工智能系统检测谎言-这就是所谓的微调。-但让我们打个比方。-想象一下大型语言模型就像-经过多年学校教育的学生-他们学习了各种知识-例如语言、概念、事实。但是当他们需要进入专业领域时-比如进入法学院或医学院-他们需要更有针对性的培训。微调就是额外的教育。-当然-大型语言模型的学习方式并不像人类那样。-但这只是为了告诉你主要思想。-然后-对于培训学生-你需要书籍、讲座、例子-对于训练大型语言模型-你需要数据集。-在我们的研究中-我们考虑了三个数据集-一个是关于个人观点-一个是关于过去的自传体记忆-一个是关于未来意图。-这些数据集已经从以前的研究中获得-包含真实的和欺骗性的陈述。-通常-你-通过要求参与者说实话或撒谎来收集这些类型的陈述。-例如-如果我是真实条件下的参与者-并且任务是-告诉我你过去的假期-那么我会告诉研究人员我以前在越南的假期-这里有一张幻灯片来证明这一点。为了欺骗对方-他们会随机挑选一些从未去过越南的人-要求你们编造一个故事-让别人相信你真的去过越南。-这就是它的典型工作方式。-你们可能知道-就像所有大学课程一样-上完课之后还要参加考试。同样-在训练我们的人工智能模型之后-我们也想对其进行测试。我们遵循的程序-实际上是典型的程序-如下所示。-因此-我们从每个数据集中随机挑选了一些语句-然后将它们分开。-因此模型在训练阶段从未见过这些陈述。-只有在培训完成后-我们才将它们用作测试-作为期末考试。但当时我们的学生是谁-在这种情况下-它是谷歌开发的一个大型语言模型"}},[n._v("#")]),n._v(' "人们的准确率并不\n比偶然水平高，和"\n抛硬币差不多。\n您可能还想知道，\n"警察、\n检察官、专家"\n甚至心理学家等专家是否\n更善于识别谎言。\n答案很复杂，\n"因为单靠经验\n似乎"\n不足以准确地识别谎言。\n这或许有帮助，但还不够。\n给你一些数字。\n"在2006年，学者们所做的一项著名的荟萃分析中\n，"\n他们发现天真的判断者的准确率\n平均约为54%。\n专家的表现仅略好一些，\n准确率约为 55%。\n（笑声）\n没什么特别的，对吧？\n而且...\n"这些数字实际上\n来自对"\n108 项研究结果的分析，这\n"意味着这些发现\n非常可靠。"\n"当然，争论\n要比这复杂得多，"\n也更加微妙。\n但这里最主要的讯息\n"是，人类并不\n擅长察觉谎言。"\n如果我们创建一种人工智能工具，让\n"每个人都能检测出\n其他人是否在说谎，那会怎样？"\n"这目前还不可能，\n所以请不要惊慌。"\n（笑声）\n"但这正是我们\n在最近的研究中尝试做的，"\n"我\n和我的杰出的同事们一起做了这项研究，"\n我需要向他们表示感谢。\n"实际上，为了让你了解\n我们在研究中所做的工作，"\n"我需要首先向你介绍\n一些技术概念"\n和这个故事的主角：\n大型语言模型。\n大型语言模型是\n"旨在以\n"\n"几乎模仿\n人类交流的方式生成自然语言输出的人工智能系统。"\n"如果你想知道我们如何教\n这些人工智能系统检测谎言，"\n"这就是所谓的\n微调。"\n但让我们打个比方。\n"想象一下大型语言模型\n就像"\n经过多年学校教育的学生，他们\n学习了各种知识，\n例如语言、概念、事实。\n但是当他们需要进入专业领域时，\n比如进入法学院或医学院，\n他们需要更有针对性的培训。\n微调就是额外的教育。\n"当然，大型语言模型的\n学习方式并不像人类那样。"\n"但这只是为了告诉你\n主要思想。"\n"然后，对于培训学生，\n你需要书籍、讲座、例子；"\n"对于训练大型语言模型，\n你需要数据集。"\n"在我们的研究中，\n我们考虑了三个数据集，"\n一个是关于个人观点，\n一个是关于过去的自传体记忆\n，一个是关于未来意图。\n"这些数据集已经\n从以前的研究中获得"\n"，包含真实的\n和欺骗性的陈述。"\n"通常，你\n"\n"通过要求参与者说实话\n或撒谎来收集这些类型的陈述。"\n"例如，如果我是\n真实条件下的参与者，"\n并且任务是\n“告诉我你过去的假期”，\n"那么我会告诉研究人员\n我以前在越南的假期，"\n这里有一张幻灯片来证明这一点。\n为了欺骗对方，\n"他们会随机挑选一些\n从未去过越南的人，"\n要求你们编造一个故事\n"，让别人相信\n你真的去过越南。"\n这就是它的典型工作方式。 你们可能知道，\n"就像所有大学课程一样，\n"\n上完课之后还要参加考试。\n同样，在训练我们的人工智能模型之后，\n我们也想对其进行测试。\n我们遵循的程序\n"实际上是典型的程序，\n如下所示。"\n"因此，我们从每个数据集中随机挑选了一些语句，\n"\n然后将它们分开。\n"因此模型在训练阶段从未见过这些陈述\n。"\n只有在培训完成后，\n我们才将它们用作测试，作为期末考试。\n但当时我们的学生是谁？\n"在这种情况下，它是谷歌开发的\n一个大型语言模型"')]),n._v(" "),e("h2",{attrs:{id:"称为-flan-t5。弗兰尼-送给朋友。-现在我们已经将所有流程的部分整合在一起-可以深入研究了。-我们的研究由三个主要实验组成。-对于第一个实验-我们分别在每个数据集上对我们的模型-flan-t5-进行了微调-。对于第二个实验-我们在两对数据集上对模型进行了微调-并在剩下的第三对数据集上对其进行了测试-并使用了所有三种可能的组合。-对于最后的最终实验-我们在通过将所有三个数据集组合在一起而获得的新的、更大的训练测试集上对模型进行了微调-。-结果非常有趣-因为我们发现在第一次实验中-flan-t5-的准确率达到了70-到-80-之间。-然而-在第二次实验中-flan-t5-的准确率下降到了近-50-。-然后-令人惊讶的是-在第三次实验中-flan-t5-又回升至近-80-。但这是什么意思呢-我们可以从这些结果中了解到什么-从实验一和实验三中-我们了解到语言模型-可以有效地将语句分类为欺骗性语句-其表现-优于人类基准-并与"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#称为-flan-t5。弗兰尼-送给朋友。-现在我们已经将所有流程的部分整合在一起-可以深入研究了。-我们的研究由三个主要实验组成。-对于第一个实验-我们分别在每个数据集上对我们的模型-flan-t5-进行了微调-。对于第二个实验-我们在两对数据集上对模型进行了微调-并在剩下的第三对数据集上对其进行了测试-并使用了所有三种可能的组合。-对于最后的最终实验-我们在通过将所有三个数据集组合在一起而获得的新的、更大的训练测试集上对模型进行了微调-。-结果非常有趣-因为我们发现在第一次实验中-flan-t5-的准确率达到了70-到-80-之间。-然而-在第二次实验中-flan-t5-的准确率下降到了近-50-。-然后-令人惊讶的是-在第三次实验中-flan-t5-又回升至近-80-。但这是什么意思呢-我们可以从这些结果中了解到什么-从实验一和实验三中-我们了解到语言模型-可以有效地将语句分类为欺骗性语句-其表现-优于人类基准-并与"}},[n._v("#")]),n._v(' ，称为 FLAN-T5。\n弗兰尼，送给朋友。\n"现在我们已经将所有\n流程的部分整合在一起，"\n可以深入研究了。\n"我们的研究\n由三个主要实验组成。"\n"对于第一个实验，\n我们分别在每个数据集上对我们的模型 FLAN-T5 进行了微调"\n。\n对于第二个实验，\n"我们\n在两对数据集上对模型进行了微调，"\n"并\n在剩下的第三对数据集上对其进行了测试，"\n"并使用了所有三种\n可能的组合。"\n对于最后的最终实验，\n"我们在通过将所有三个数据集组合在一起而获得的\n新的、更大的训练测试集上对模型进行了微调"\n"\n。"\n结果非常有趣，\n"因为我们发现\n在第一次实验中，"\n"FLAN-T5 的准确率达到了\n70% 到 80% 之间。"\n然而，在第二次实验中，\n"FLAN-T5 的准确率下降\n到了近 50%。"\n"然后，令人惊讶的是，\n在第三次实验中，"\nFLAN-T5 又回升至近 80%。\n但这是什么意思呢？\n我们可以从这些结果中了解到什么？\n从实验一和实验三中，\n我们了解到语言模型\n"可以有效地将\n语句分类为欺骗性语句，其表现"\n优于人类基准，\n"并与\n"')]),n._v(" "),e("p",[n._v('"先前研究\n在相同数据集上训练的机器学习和深度学习模型保持一致。"\n然而，从第二个实验中，\n我们看到语言模型很难\n"将这些知识、\n这种跨不同情境的学习概括化。"\n这显然是因为\n"不存在一条\n"\n可以轻易应用于所有情况的普遍欺骗规则，\n"但欺骗的语言线索\n却与具体情况有关。"\n从第三个实验中，\n我们了解到，实际上语言模型\n"可以很好地推广\n到不同的语境中，"\n"只要它们\n"\n在训练阶段曾接触过示例。\n我认为这听起来是个好消息。\n"但虽然这意味着语言模型\n可以有效地应用于"\n"\n谎言检测的实际应用，但"\n"需要更多的复制，\n因为单一的研究是远远不够的，"\n"以便从明天开始我们都可以\n在智能手机上拥有这些人工智能系统，"\n并开始检测其他人的谎言。\n"但作为一名科学家，\n我拥有丰富的想象力，"\n并且愿意去实现远大的梦想。\n"我也想带你一起\n踏上这段未来之旅。"\n"所以请和我一起想象一下\n生活在这样一个世界里，"\n"谎言检测技术\n已经很好地融入到我们的生活，"\n"从国家安全\n到社交媒体，一切都将变得更加安全。"\n"想象一下，如果有一个人工智能系统\n能够真正识别虚假观点。"\n从明天起，我们就能知道\n"什么时候政客\n实际上是在说一套话，"\n而什么时候他真正相信另一套话。\n（笑声）\n那么在安全公告板上，\n"当人们被问及\n"\n"他们跨越边境\n或登机的意图和原因时，情况又如何呢？"\n有了这些系统，\n"我们实际上可以在\n恶意行为"\n发生之前就发现它们。\n那么招聘流程是怎样的呢？\n（笑声）\n我们已经听说过这件事了。\n"但实际上，公司\n可以使用这种人工智能"\n"来区分那些\n真正对职位充满热情的人和"\n"那些只是为了\n获得工作而说些正确的话的人。"\n最后，我们有社交媒体。\n"诈骗者试图欺骗您\n或窃取您的身份。"\n一切都消失了。\n"而其他人可能会对\n虚假新闻发表一些看法，"\n"那么语言模型\n就可以完美地自动阅读新闻，"\n将其标记为欺骗性或虚假的，\n"我们甚至可以为用户提供他们\n"\n所读信息的可信度分数。\n这听起来像是一个美好的未来，对吧？\n（笑声）\n是的，但是……\n所有伟大的进步都伴随着风险。\n尽管我对这个未来感到兴奋，但\n我认为我们需要小心。\n在我看来，如果我们不谨慎的话，\n我们最终可能会陷入一个\n"人们\n盲目相信人工智能输出的世界。"\n"我担心这意味着\n人们会更有可能"\n"指责别人撒谎，\n仅仅因为人工智能这么说。"\n而且我不是唯一持有这种观点的人，\n因为另一项研究已经证明了这一点。\n"此外，如果我们完全\n依赖这种测谎技术"\n来判断别人是否撒谎，\n"我们就有可能失去\n社会中另一个重要的核心价值。"\n我们失去了信任。\n我们将不再需要信任人类，\n"因为我们\n只需让人工智能为我们再检查一遍。"\n"但我们真的愿意\n盲目相信人工智能"\n并放弃批判性思维吗？\n"我认为这就是\n我们需要避免的未来。"\n"希望未来\n会有更多的可解释性。"\n我接下来就要告诉你我的意思。 与\n我们在网上查看评论时类似，\n"我们既可以\n查看各个地方的星级总数，"\n"也可以更详细地查看\n正面和负面的评论，"\n"并尝试了解\n哪些是积极的一面，"\n哪些可能出了问题，\n"最终形成\n我们自己的想法，"\n确定那是我们想去的地方、\n我们想去的地方。\n"同样，想象一下这样一个世界，\n人工智能不仅能得出结论，"\n"还能为其决策提供清晰\n易懂的解释"\n。\n我设想的未来是，\n这种测谎技术\n"不仅能为我们提供\n简单的判断，"\n"还能清楚地解释\n为什么它认为别人在说谎。"\n我希望在未来，\n"测谎技术或者人工智能技术\n能够融入我们的生活"\n，\n但与此同时，\n我们仍然能够批判性地思考\n"，决定何时应该\n相信人工智能的判断"\n，何时应该质疑它。\n总而言之，\n"我认为未来使用人工智能\n进行测谎"\n"不仅关乎\n技术进步，"\n"还关乎增进我们的理解\n和培养信任。"\n"这是为了开发一些工具，\n它们不会取代人类的判断力，"\n而是会增强人类的判断力，\n确保我们能够掌控局势。\n"不要\n盲目依赖科技走进未来。"\n"让我们致力于深刻理解\n和道德使用，"\n追求真理。\n（掌声）\n谢谢。')])])}),[],!1,null,null,null);e.default=a.exports}}]);