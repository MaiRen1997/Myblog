(window.webpackJsonp=window.webpackJsonp||[]).push([[58],{1031:function(t,v,a){"use strict";a.r(v);var _=a(7),r=Object(_.a)({},(function(){var t=this,v=t._self._c;return v("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[v("h2",{attrs:{id:"大模型的演变与概念"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#大模型的演变与概念"}},[t._v("#")]),t._v(" 大模型的演变与概念")]),t._v(" "),v("h3",{attrs:{id:"大模型的演变"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#大模型的演变"}},[t._v("#")]),t._v(" 大模型的演变")]),t._v(" "),v("h4",{attrs:{id:"人工智能"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#人工智能"}},[t._v("#")]),t._v(" 人工智能")]),t._v(" "),v("p",[t._v("人工只能是一个广泛设计计算机科学、数据分析、统计学、等多个学科领域")]),t._v(" "),v("h4",{attrs:{id:"机器学习"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#机器学习"}},[t._v("#")]),t._v(" 机器学习")]),t._v(" "),v("ol",[v("li",[v("p",[t._v("分类")]),t._v(" "),v("ol",[v("li",[v("p",[t._v("监督学习")]),t._v(" "),v("p",[t._v("人为的教会该怎么做，告诉其步骤，让其执行")]),t._v(" "),v("p",[t._v("如： 这是橘子， 黄的，圆的，带有小点；这是苹果，红色，圆的；这是香蕉，黄的，长条的，半圆的。\n然后拿出来一个橘子，让其辨别， 其发现是黄的，圆的，就认为是橘子了")])]),t._v(" "),v("li",[v("p",[t._v("无监督学习")]),t._v(" "),v("p",[t._v("不告诉其步骤、特征，通过指导其方法，让其自己观察，自己总结规律，进行学习\n如，判断水果，你应该从颜色，形状等进行判断")])]),t._v(" "),v("li",[v("p",[t._v("强化学习")]),t._v(" "),v("p",[t._v("不告诉任何信息，只告诉其结果，让其自己总结规律，自己学习\n如： AI说： 这是个苹果马？ 回答：不是， AI：是橘子吗？ 回答：是， AI： 黄色、圆的是橘子")])])])])]),t._v(" "),v("h4",{attrs:{id:"深度学习"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#深度学习"}},[t._v("#")]),t._v(" 深度学习")]),t._v(" "),v("p",[t._v("深度学习是机器学习的一个分支，主要使用神经网络模型(由多个隐藏层组成)，对数据进行学习和表示")]),t._v(" "),v("p",[t._v("深度学习算法试图模拟人类大脑的工作方式，其灵感来源于神经生物学，它通过对大量数据的学习，自动提取出数据的高层次特征和模式，从而实现图像识别语音识别、自然语言处理等任务。按照架构的不同，神经网络可以分为:"),v("strong",[t._v("卷积神经网络(CNNS)、循环神经网络(RNNs)、Transformer网络")]),t._v("等等\n同样是区分不同水果，这次你带着孩子去了超市那里有各种不同的水果，你没有解释每种水果的特点只是给孩子指出了哪些是苹果哪些是香蕉，他通过观察和比较，慢慢学会了辨认各种水果。在这个过程中，孩子的大脑(在这里比喻为深度学习模型)自动从复杂的视觉、嗅觉等信号中提取层次化的特征。比如圆形、条纹、颜色深浅、气味等，从而达到识别水果的目的。")]),t._v(" "),v("h4",{attrs:{id:"生成式人工智能-aigc"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#生成式人工智能-aigc"}},[t._v("#")]),t._v(" 生成式人工智能(AIGC)")]),t._v(" "),v("p",[t._v("生成式人工智能又是深度学习中快速增长的子集，他们使用了大模型提供支持，在大量原始、未标记的数据基础上对深度学习模型进行预训练，使得机器能够理解语言甚至图像，并能够根据需要自动生成内容")]),t._v(" "),v("h3",{attrs:{id:"大模型的几个概念"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#大模型的几个概念"}},[t._v("#")]),t._v(" 大模型的几个概念")]),t._v(" "),v("ol",[v("li",[t._v("AGI：全称Artificial General Intelligence，译名“通用人工智能”")]),t._v(" "),v("li",[t._v("‌AIGC：全称Artificial Intelligence Generated Content，译名“人工智能生成内容”")]),t._v(" "),v("li",[t._v("‌LLM：全称Large Language Model‌，译名“大型语言模型”‌‌")])]),t._v(" "),v("h3",{attrs:{id:"大模型的使用与训练"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#大模型的使用与训练"}},[t._v("#")]),t._v(" 大模型的使用与训练")]),t._v(" "),v("h4",{attrs:{id:"大模型使用"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#大模型使用"}},[t._v("#")]),t._v(" 大模型使用")]),t._v(" "),v("p",[t._v("输入prompt，得出答案")]),t._v(" "),v("p",[t._v("因此，我们需要提高书写prompt的能力")]),t._v(" "),v("h4",{attrs:{id:"大模型训练"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#大模型训练"}},[t._v("#")]),t._v(" 大模型训练")]),t._v(" "),v("ol",[v("li",[v("p",[t._v("预训练")]),t._v(" "),v("p",[t._v("提升我们的底层学习能力，类似于初高中，要学习很多知识，虽然这些知识，在大学、社会上用不到")]),t._v(" "),v("p",[t._v("预训练的过程类似于从婴儿成长为中学生的阶段，在这个阶段我们会学习各种各样的知识，我们的语言习惯、知识体系等重要部分都会形成;对于大型来说，在这个阶段它会学习各种不同种类的语料，学习到语言的统计规律和一般知识。但是大模型在这个阶段只是学会了补全句子，却没有学会怎么样去领会人类的意图，假设我们向预训练的模型提问:“埃菲尔铁塔在哪个国家?”模型有可能不会回答“法国”，而是根据它看到过的语料进行输出:“东方明珠在哪个城市?”这显然不是一个好的答案，因此我们需要让它能够去遵循人类的指示进行回答，这个步骤就是SFT(监督微调)")])]),t._v(" "),v("li",[v("p",[t._v("SFT(监督微调)")]),t._v(" "),v("p",[t._v("类似于大学学习，通过专业课学习，来使自己的能力更符合该专业，该行业的发展")])]),t._v(" "),v("li",[v("p",[t._v("RLHF(基于人类反馈的强化学习)")]),t._v(" "),v("p",[t._v("即使经过专业学习，在工作中，仍有很多问题，无法通过课本知识解决，需要通过请教别人，学习别人解决问题的能力，当这种能力经过不断的反馈、实践，最后达到提升自己的目的")]),t._v(" "),v("p",[t._v("RLHF的过程类似于从大学生步入职场的阶段，在这个阶段我们会开始进行工作但是我们的工作可能会受到领导和客户的表扬，也有可能会受到批评，我们会根据反馈调整自己的工作方法，争取在职场获得更多的正面反馈。对于大模型来说，在这个阶段它会针对同一问题进行多次回答，人类会对这些回答打分，大模型会在此阶段学习到如何输出分数最高的回答，使得回答更符合人类的偏好。")])])]),t._v(" "),v("h3",{attrs:{id:"大模型的特点和分类"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#大模型的特点和分类"}},[t._v("#")]),t._v(" 大模型的特点和分类")]),t._v(" "),v("h4",{attrs:{id:"基础模型-大模型-的特点"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#基础模型-大模型-的特点"}},[t._v("#")]),t._v(" 基础模型(大模型)的特点")]),t._v(" "),v("ol",[v("li",[v("p",[t._v("规模和参数大")]),t._v(" "),v("p",[t._v("大模型通过其庞大的规模(拥有从数亿到数千亿级别的参数数量)来捕获复杂的数据模式，使得它们能够理解和生成极其丰富的信息。")])]),t._v(" "),v("li",[v("p",[t._v("适应性和灵活性强")]),t._v(" "),v("p",[t._v("模型具有很强的适应性和灵活性，能够通过微调(fine-tune)或少样本学习高效地迁移到各种下游任务，有很强的跨域能力。")])]),t._v(" "),v("li",[v("p",[t._v("广泛数据集的预训练")]),t._v(" "),v("p",[t._v("大模型使用大量多样化的数据进行预训练，以学习广泛的知识表示，能够掌握语言、图像等数据的通用特征。")])]),t._v(" "),v("li",[v("p",[t._v("计算资源需求大")]),t._v(" "),v("p",[t._v("巨大的模型规模带来了高昂的计算和资源需求，包括但不限于数据存储、训练时间、能量消耗和硬件设施。")])])]),t._v(" "),v("h4",{attrs:{id:"大模型分类"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#大模型分类"}},[t._v("#")]),t._v(" 大模型分类")]),t._v(" "),v("ol",[v("li",[v("p",[t._v("大语言模型(LLM)")]),t._v(" "),v("p",[t._v("这类大模型专注于自然语言处理(NLP)，旨在处理语言、文章、对话等自然语言文本。它们通常基于深度学习架构(如Transformer模型)经过大规模文本数据集训练而成，能够捕捉语言的复杂性，包括语法、语义、语境以及蕴含的文化和社会知识。语言大模型典型应用包括文本生成、问答系统、文本分类、机器翻译、对话系统等。示例包括:1.GPT系列(OpenAI):如GPT-3、GPT-3.5、GPT-4等。\nBard(Google):谷歌推出的大型语言模型用于提供信息丰富的、有创意的文本输出。通义千问(阿里云):阿里云自主研发的超大规模的语言模型。")])]),t._v(" "),v("li",[v("p",[t._v("多模态模型")]),t._v(" "),v("p",[t._v("多模态大模型能够同时处理和理解来自不同感知通道\n(如文本、图像、音频、视频等)的数据，并在这些模态之间建立关联和交互。它们能够整合不同类型的输入信息，进行跨模态推理、生成和理解任务。多模态大模型的应用涵盖视觉问答、图像描述生成、跨模态检索、多媒体内容理解等领域。")]),t._v(" "),v("ol",[v("li",[t._v("计算机视觉模型")]),t._v(" "),v("li",[t._v("音频处理模型")]),t._v(" "),v("li",[t._v("视频处理模型")]),t._v(" "),v("li",[t._v("......")])])])]),t._v(" "),v("h3",{attrs:{id:"大模型的工作流程"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#大模型的工作流程"}},[t._v("#")]),t._v(" 大模型的工作流程")]),t._v(" "),v("h4",{attrs:{id:"分词化与词表映射"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#分词化与词表映射"}},[t._v("#")]),t._v(" 分词化与词表映射")]),t._v(" "),v("ol",[v("li",[v("p",[t._v("什么是分词化")]),t._v(" "),v("p",[t._v("分词化(Tokenization)是自然语言处理(NLP)中的重要概念，\"它是将段落和句子分割成更小的分词(token)的过程。举一个实际的例子，以下是一个英文句子:\nI want to study ACA.为了让机器理解这个句子，对字符串执行分词化，将其分解为独立的单元。使用分词\n化，我们会得到这样的结果:['l' ,'want' ,'to' ,'study' ,'ACA' ,'.]将一个句子分解成更小的、独立的部分可以帮助计算机理解句子的各个部分，以及它们在上下文中的作用，这对于进行大量上下文的分析尤其重要。分词化有不同的粒度分类:\n-词粒度(Word-LevelTokenization)分词化，如上文中例子所示，适用于大多数西方语言，如英语。\n-字符粒度(Character-Level)分词化是中文最直接的分词方法，它是以单个汉字为单位进行分词化。\n-子词粒度(Subword-Level)分词化，它将单词分解成更小的单位，比如词根、词缀等。这种方法对于处理新词(比如专有名词、网络用语等)特别有效，因为即使是新词，它的组成部分(子词)很可能已经存在于词表中了。\n每一个token都会通过预先设置好的词表，映射为一个 tokenid，这是token 的“身份证”一句话最终会被表示为一个元素为token id的列表，供计算机进行下一步处理")]),t._v(" "),v("p",[v("img",{attrs:{src:a(511),alt:""}})])])]),t._v(" "),v("h4",{attrs:{id:"文本生成过程"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#文本生成过程"}},[t._v("#")]),t._v(" 文本生成过程")]),t._v(" "),v("p",[t._v("大语言模型的工作概括来说是根据给定的文本预测下一个token。对我们来说，看似像在对大模型提问，但实际上是给了大模型一串提示文本，让它可以对后续的文本进行推理。大模型的推理过程不是一步到位的，当大模型进行推理时，它会基于现有的token，根据概率最大原则预测出下一个最有可能的token，然后将该预测的token加入到输入序列中，并将更新后的输入序列继续输入大模型预测下一个token，这个过程叫做自回归。直到输出特殊token(如"),v("EOS",[t._v("，end of sentence，专门用来控制推理何时结束)或输出长度达到阈值。")])],1),t._v(" "),v("p",[v("img",{attrs:{src:a(512),alt:""}})]),t._v(" "),v("h3",{attrs:{id:"大模型的应用"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#大模型的应用"}},[t._v("#")]),t._v(" 大模型的应用")]),t._v(" "),v("ol",[v("li",[v("p",[t._v("阿里的通义千问")]),t._v(" "),v("p",[t._v("通义千问是阿里巴巴超大规模语言模型创作需求，甚至还能与你进行趣味互动\n能帮你写文案、代码，解答问题，提升工作效率，满足个性化")]),t._v(" "),v("ol",[v("li",[t._v("查询当日天气")]),t._v(" "),v("li",[t._v("解读复杂图表")])])])])])}),[],!1,null,null,null);v.default=r.exports},511:function(t,v,a){t.exports=a.p+"assets/img/01.splitWords.017b6bd6.png"},512:function(t,v,a){t.exports=a.p+"assets/img/02.generateProcess.b7d79a35.png"}}]);