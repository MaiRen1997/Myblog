(window.webpackJsonp=window.webpackJsonp||[]).push([[359],{862:function(n,e,t){"use strict";t.r(e);var a=t(7),o=Object(a.a)({},(function(){var n=this,e=n._self._c;return e("ContentSlotsDistributor",{attrs:{"slot-key":n.$parent.slotKey}},[e("p",[n._v("Now, I haven't met most of you or really any of you,\nbut I feel a really good vibe in the room.")]),n._v(" "),e("p",[n._v("(Laughter)")]),n._v(" "),e("p",[n._v("And so I think I'd like to treat you all to a meal.")]),n._v(" "),e("p",[n._v("What do you think?")]),n._v(" "),e("p",[n._v("Yes? Great, so many new friends.")]),n._v(" "),e("p",[n._v("So we're going to go to this cafe,\nthey serve sandwiches.")]),n._v(" "),e("p",[n._v("And the sandwiches are really delicious.")]),n._v(" "),e("p",[n._v("But I have to tell you that sometimes they make people really, really sick.")]),n._v(" "),e("p",[n._v("(Laughter)\nAnd we don't know why.")]),n._v(" "),e("p",[n._v("Because the cafe won't tell us how they make the sandwich,\nthey won't tell us about the ingredients.")]),n._v(" "),e("p",[n._v("And then the authorities have no way to fix the problem.")]),n._v(" "),e("p",[n._v("But the offer still stands.")]),n._v(" "),e("p",[n._v("So who wants to get a sandwich?")]),n._v(" "),e("p",[n._v("(Laughter)\nSome brave souls, we can talk after.")]),n._v(" "),e("p",[n._v("But for the rest of you, I understand.")]),n._v(" "),e("p",[n._v("You don't have enough information\nto make good choices about your safety\nor even fix the issue.")]),n._v(" "),e("p",[n._v("Now, before I further the anxiety here, I'm not actually trying to make you sick,\nbut this is an analogy to how we're currently making algorithmic systems,\nalso known as artificial intelligence or AI.")]),n._v(" "),e("p",[n._v("Now, for those who haven't thought about the relationship\nbetween AI and sandwiches, don't worry about it,\nI'm here for you, I'm going to explain.")]),n._v(" "),e("p",[n._v("You see, AI systems, they provide benefit to society.")]),n._v(" "),e("p",[n._v("They feed us,\nbut they're also inconsistently making us sick.")]),n._v(" "),e("p",[n._v("And we don't have access to the ingredients that go into the AI.\nAnd so we can't actually address the issues.\nWe also can't stop eating AI\nlike we can just stop eating a shady sandwich\nbecause it's everywhere,\nand we often don't even know that we're encountering a system\nthat's algorithmically based.\nSo today, I'm going to tell you about some of the AI trends that I see.\nI'm going to draw on my experience building these systems\nover the last two decades to tell you about the tools\nthat I and others have built to look into these AI ingredients.\nAnd finally, I'm going to leave you with three principles\nthat I think will give us a healthier relationship\nto the companies that build artificial intelligence.\nI'm going to start with the question, how did we get here?\nAI is not new.\nWe have been living alongside AI for two decades.\nEvery time that you apply for something online,\nyou open a bank account or you go through passport control,\nyou're encountering an algorithmic system.\nWe've also been living with the negative repercussions of AI for 20 years,\nand this is how it makes us sick.\nThese systems get deployed on broad populations,\nand then certain subsets end up getting negatively disparately impacted,\nusually on the basis of race or gender or other characteristics.\nWe need to be able to understand the ingredients to these systems\nso that we can address the issues.\nSo what are the ingredients to an AI system?\nWell, data fuels the AI.\nThe AI is going to look like the data that you gave it.\nSo for example,\nif I want to make a risk-assessment system for diabetes,\nmy training data set might be adults in a certain region.\nAnd so I'll build that system,\nit'll work really well for those adults in that region.\nBut it does not work for adults in other regions\nor maybe at all for children.\nSo you can imagine if we deploy this for all those populations,\nthere are going to be a lot of people who are harmed.\nWe need to be able to understand the quality of the data before we use it.\nBut I'm sorry to tell you that we currently live\nin what I call the Wild West of data.\nIt's really hard to assess quality of data before you use it.\nThere are no global standards for data quality assessment,\nand there are very few data regulations around how you can use data\nand what types of data you can use.\nThis is kind of like in the food safety realm.\nIf we couldn't understand where the ingredients were sourced,\nwe also had no idea whether they were safe for us to consume.\nWe also tend to stitch data together,\nand every time we stitch this data together,\nwhich we might find on the internet, scrape, we might generate it,\nwe could source it.\nWe lose information about the quality of the data.\nAnd the folks who are building the models\nare not the ones that found the data.\nSo there's further information that's lost.\nNow, I've been asking myself a lot of questions\nabout how can we understand the data quality before we use it.\nAnd this emerges from two decades of building these kinds of systems.\nThe way I was trained to build systems is similar to how people do it today.\nYou build for the middle of the distribution.\nThat's your normal user.\nSo for me, a lot of my training data sets\nwould include information about people from the Western world who speak English,\nwho have certain normative characteristics.\nAnd it took me an embarrassingly long amount of time\nto realize that I was not my own user.\nSo I identify as non-binary, as mixed race,\nI wear a hearing aid\nand I just wasn't represented in the data sets that I was using.\nAnd so I was building systems that literally didn't work for me.\nAnd for example, I once built a system that repeatedly told me\nthat I was a white Eastern-European lady.\nThis did a real number on my identity.\n(Laughter)\nBut perhaps even more worrying,\nthis was a system to be deployed in health care,\nwhere your background can determine things like risk scores for diseases.\nAnd so I started to wonder,\ncan I build tools and work with others to do this\nso that I can look inside of a dataset before I use it?\nIn 2018, I was part of a fellowship at Harvard and MIT,\nand I, with some colleagues, decided to try to address this problem.\nAnd so we launched the Data Nutrition Project,\nwhich is a research group and also a nonprofit\nthat builds nutrition labels for datasets.\nSo similar to food nutrition labels,\nthe idea here is that you can look inside of a data set before you use it.\nYou can understand the ingredients,\nsee whether it's healthy for the things that you want to do.\nNow this is a cartoonified version of the label.\nThe top part tells you about the completion of the label itself.\nAnd underneath that you have information about the data,\nthe description, the keywords, the tags,\nand importantly, on the right hand side,\nhow you should and should not use the data.\nIf you could scroll on this cartoon,\nyou would see information about risks and mitigation strategies\nacross a number of vectors.\nAnd we launched this with two audiences in mind.\nThe first audience are folks who are building AI.\nSo they’re choosing datasets.\nWe want to help them make a better choice.\nThe second audience are folks who are building datasets.\nAnd it turns out\nthat when you tell someone they have to put a label on something,\nthey think about the ingredients beforehand.\nThe analogy here might be,\nif I want to make a sandwich and say that it’s gluten-free,\nI have to think about all the components as I make the sandwich,\nthe bread and the ingredients, the sauces.\nI can't just put it on a sandwich and put it in front of you\nand tell you it's gluten-free.\nWe're really proud of the work that we've done.\nWe launched this as a design and then a prototype\nand ultimately a tool for others to make their own labels.\nAnd we've worked with experts at places like Microsoft Research,\nthe United Nations and professors globally\nto integrate the label and the methodology\ninto their work flows and into their curricula.\nBut we know it only goes so far.\nAnd that's because it's actually really hard to get a label\non every single dataset.\nAnd this comes down to the question\nof why would you put a label on a dataset to begin with?\nWell, the first reason is not rocket science.\nIt's that you have to.\nAnd this is, quite frankly, why food nutrition labels exist.\nIt's because if they didn't put them on the boxes, it would be illegal.\nHowever, we don't really have AI regulation.\nWe don't have much regulation around the use of data.\nNow there is some on the horizon.\nFor example, the EU AI Act just passed this week.\nAnd although there are no requirements around making the training data available,\nthey do have provisions for creating transparency labeling\nlike the dataset nutrition label, data sheets, data statements.\nThere are many in the space.\nWe think this is a really good first step.\nThe second reason that you might have a label on a dataset\nis because it is a best practice or a cultural norm.\nThe example here might be how we're starting to see\nmore and more food packaging and menus at restaurants\ninclude information about whether there's gluten.\nThis is not required by law,\nalthough if you do say it, it had better be true.\nAnd the reason that people are adding this to their menus\nand their food packaging\nis because there's an increased awareness of the sensitivity\nand kind of the seriousness of that kind of an allergy or condition.\nSo we're also seeing some movement in this area.\nFolks who are building datasets are starting to put nutrition labels,\ndata sheets on their datasets.\nAnd people who are using data are starting to request the information.\nThis is really heartening.\nAnd you might say, \"Kasia, why are you up here?\nEverything seems to be going well, seems to be getting better.\"\nIn some ways it is.\nBut I'm also here to tell you that our relationship to data\nis getting worse.\nNow the last few years have seen a supercharged interest\nin gathering datasets.\nCompanies are scraping the web.\nThey're transcribing millions of hours of YouTube videos into text.\nBy some estimates, they'll run out of information on the internet by 2026.\nThey're even considering buying publishing houses\nso they can get access to printed text and books.\nSo why are they gathering this information?\nWell, they need more and more information\nto train a new technique called generative AI.\nI want to tell you about the size of these datasets.\nIf you look at GPT-3, which is a model that launched in 2020,\nthe training dataset included 300 billion words, or parts of words.\nNow for context, the English language contains less than a million words.\nJust three years later, DBRX was launched,\nwhich was trained on eight trillion words.\nSo 300 billion to eight trillion in three years.\nAnd the datasets are getting bigger.\nNow with each successive model launch,\nthe datasets are actually less and less transparent.\nAnd even we have access to the information,\nit's so big, it's so hard to look inside without any kind of transparency tooling.\nAnd the generative AI itself is also causing some worries.\nAnd you've probably encountered this technique through ChatGPT.\nI don't need to know what you do on the internet,\nthat's between you and the internet,\nbut you probably know, just like I do,\nhow easy it is to create information using ChatGPT\nand other generative AI technologies\nand to put that out onto the web.\nAnd so we're looking at a situation\nin which we're going to encounter lots of information\nthat's algorithmically generated but we won't know it\nand we won't know whether it's true.\nAnd this increases the scale of the potential risks and harms from AI.\nNot only that, I'm sorry,\nbut the models themselves are getting controlled\nby a smaller and smaller number of private actors in US tech firms.\nSo this is the models that were launched last year, in 2023.\nAnd you can see most of them are pink, meaning they came out of industry.\nAnd if you look at this over time, more and more are coming out of industry\nand fewer and fewer are coming out of all the other sectors combined,\nincluding academia and government,\nwhere technology is often launched in a way\nthat's more easy to be scrutinized.\nSo if we go back to our cafe analogy,\nthis is like you have a small number of private actors\nwho own all the ingredients,\nthey make all the sandwiches globally,\nand there's not a lot of regulation.\nAnd so at this point you're probably scared\nand maybe feeling a little uncomfortable.\nWhich is ironic because a few minutes ago, I was going to get you all sandwiches\nand you said yes.\nThis is why you should not accept food from strangers.\nBut I wouldn't be up here if I weren't also optimistic.\nAnd that's because I think we have momentum\nbehind the regulation and the culture changes.\nEspecially if we align ourselves with three basic principles\nabout how corporations should engage with data.\nThe first principle is that companies that gather data should tell us\nwhat they're gathering.\nThis would allow us to ask questions like, is it copyrighted material?\nIs that information private?\nCould you please stop?\nIt also opens up the data to scientific inquiry.\nThe second principle is that companies that are gathering our data should tell us\nwhat they're going to do with it before they do anything with it.\nAnd by requiring that companies tell us their plan,\nthis means that they have to have a plan,\nwhich would be a great first step.\nIt also probably would lead to the minimization of data capture,\nbecause they wouldn't be able to capture data\nif they didn't know what they were already going to do with it.\nAnd finally, principle three,\ncompanies that build AI should tell us about the data\nthat they use to train the AI.\nAnd this is where dataset nutrition labels\nand other transparency labeling comes into play.\nYou know, in the case where the data itself won't be made available,\nwhich is most of the time, probably,\nthe labeling is critical for us to be able to investigate the ingredients\nand start to find solutions.\nSo I want to leave you with the good news,\nand that is that the data nutrition projects and other projects\nare just a small part of a global movement\ntowards AI accountability.\nDataset Nutrition Label and other projects are just a first step.\nRegulation's on the horizon,\nthe cultural norms are shifting,\nespecially if we align with these three basic principles\nthat companies should tell us what they're gathering,\ntell us what they're going to do with it before they do anything with it,\nand that companies that are building AI\nshould explain the data that they're using to build the system.\nWe need to hold these organizations accountable\nfor the AI that they're building\nby asking them, just like we do with the food industry,\nwhat's inside and how did you make it?\nOnly then can we mitigate the issues before they occur,\nas opposed to after they occur.\nAnd in doing so, create an integrated algorithmic internet\nthat is healthier for everyone.\nThank you.\n(Applause)")]),n._v(" "),e("p",[n._v('"现在，我还没有见过你们中的大多数人，\n也没有见过你们中的任何一个人，"\n但我感觉房间里的气氛非常好。\n（笑声）\n"所以我想请\n大家吃一顿饭。"\n你怎么认为？\n是的？ 太好了，这么多新朋友。\n所以我们要去这家咖啡馆，\n他们提供三明治。\n而且三明治真的很好吃。\n"但我必须告诉你，有时\n它们会让人真的非常难受。"\n（笑声）\n我们不知道为什么。\n"因为咖啡馆不会告诉我们\n他们如何制作三明治，也"\n不会告诉我们成分。\n"然后当局就\n没有办法解决这个问题。"\n但优惠仍然有效。\n那么谁想吃三明治呢？\n（笑声）\n一些勇敢的人，我们可以聊聊。\n但对于你们其他人，我理解。\n您没有足够的信息\n来就您的安全做出正确的选择，\n甚至无法解决问题。\n"现在，在我进一步加剧焦虑之前，\n我实际上并不是想让你生病，"\n"但这与我们\n目前如何制作算法系统（"\n"也称为\n人工智能或人工智能）进行了类比。"\n"现在，对于那些还没有思考\n过"\n"人工智能和三明治之间关系的人，\n别担心，"\n我在这里为你解释。\n"你看，人工智能系统，\n它们为社会带来好处。"\n它们为我们提供食物，\n"但也时常\n让我们生病。"\n"而且我们无法获得\n人工智能的成分。"\n"所以我们无法真正\n解决这些问题。"\n我们也无法停止吃人工智能，\n"就像我们不能停止\n吃可疑的三明治一样，"\n因为它无处不在，\n"而且我们常常甚至不知道\n我们正在遇到一个基于"\n算法的系统。\n"所以今天，我将向大家介绍\n我所看到的一些人工智能趋势。"\n"我将\n"\n"利用过去二十年构建这些系统的经验，\n向您介绍"\n"我和其他人为\n研究这些人工智能成分而构建的工具。"\n"最后，我将向大家介绍\n三项原则，"\n"我认为这将使我们\n"\n"与\n构建人工智能的公司建立更健康的关系。"\n"我首先要问一个问题：\n我们是如何走到这一步的？"\n人工智能并不新鲜。\n"我们与\n人工智能一起生活了二十年。"\n"每次你\n在网上申请东西、"\n"开立银行账户\n或通过护照检查时，"\n你都会遇到一个算法系统。\n"\n20 年来，我们一直承受着人工智能的负面影响，"\n这就是它让我们生病的原因。\n"这些系统被部署\n在广泛的人群中，"\n"然后某些子集最终会受到不同的\n负面影响，"\n"通常是基于种族\n、性别或其他特征。"\n"我们需要能够了解\n这些系统的组成部分，"\n以便我们能够解决问题。\n"那么人工智能系统的组成部分是什么\n？"\n好吧，数据为人工智能提供动力。\n"人工智能将看起来\n像你提供给它的数据。"\n例如，\n"如果我想做一个糖尿病风险评估\n系统，"\n"我的训练数据集可能是\n某个地区的成年人。"\n所以我将建立这个系统，\n"它对于\n该地区的成年人来说非常有效。"\n"但它对\n其他地区的成年人不起作用，"\n甚至对儿童根本不起作用。\n"所以你可以想象，如果我们\n为所有这些人群部署这个，"\n"将会有\n很多人受到伤害。 在使用数据之前，"\n"我们需要能够了解\n数据的质量。"\n"但我很遗憾地告诉您，\n我们目前生活"\n在我所说的数据狂野西部。\n"\n在使用数据之前评估数据的质量确实很困难。"\n"\n数据质量评估没有全球标准，"\n"\n关于如何使用数据"\n以及可以使用什么类型的数据法规也很少。\n"这有点像\n食品安全领域。"\n"如果我们无法了解\n这些成分的来源，"\n"我们也不知道\n它们是否可以安全食用。"\n我们还倾向于将数据拼接在一起，\n"每次我们将\n这些数据拼接在一起时，"\n"我们可能会在互联网上找到这些数据，\n刮擦，我们可能会生成它，"\n我们可以获取它。\n"我们丢失了\n有关数据质量的信息。"\n构建模型的人\n并不是发现数据的人。\n"所以还有更多的\n信息丢失了。"\n"现在，我一直在问自己\n很多问题，在"\n"\n使用数据之前如何了解数据质量。"\n"这是二十年\n来构建此类系统的结果。"\n"我接受构建系统培训的方式\n与今天人们的方式类似。"\n"您为\n分布的中间构建。"\n那是你的普通用户。\n因此，对我来说，我的很多训练数据集\n"都包含\n来自西方世界的说英语的人的信息，"\n"这些人具有某些\n规范特征。"\n"我花了很\n长一段时间才"\n意识到我不是我自己的用户。\n"因此，我认为自己是非二元性别，\n是混血儿，"\n我戴着助听器，\n"只是没有出现\n在我使用的数据集中。"\n"所以我正在构建的系统\n实际上并不适合我。"\n"例如，我曾经建立了一个系统，\n它反复告诉我，"\n我是一位东欧白人女士。\n这对我的身份产生了真实的影响。\n（笑声）\n但也许更令人担忧的是，\n"这是一个\n部署在医疗保健领域的系统，"\n"你的背景可以决定\n诸如疾病风险评分之类的事情。"\n所以我开始想知道，\n"我可以构建工具并与\n其他人合作来完成此操作，"\n"以便我可以\n在使用数据集之前查看它的内部情况吗？"\n"2018 年，我成为\n哈佛大学和麻省理工学院的研究员，"\n"我和一些同事\n决定尝试解决这个问题。"\n"因此，我们启动了\n数据营养项目，"\n"这是一个研究小组，\n也是一个"\n"\n为数据集构建营养标签的非营利组织。"\n与食品营养标签类似，\n"这里的想法是您可以\n在使用数据集之前查看其内部。"\n您可以了解其成分，\n"看看它是否适合\n您想做的事情。"\n"现在这是\n该标签的卡通化版本。"\n"顶部部分告诉您\n标签本身的完成情况。"\n"在其下方，您可以\n了解有关数据、"\n描述、关键字、标签的信息，\n重要的是，在右侧，您可以了解\n"应该如何使用\n和不应该如何使用数据。"\n如果您可以滚动此漫画，\n"您会看到有关多个向量的\n风险和缓解策略的信息"\n。\n"我们推出这个产品时\n考虑到了两个受众。 第"\n"一批受众是\n正在构建人工智能的人们。"\n所以他们正在选择数据集。\n我们希望帮助他们做出更好的选择。\n"第二个受众是\n正在构建数据集的人。 事实"\n证明，\n"当你告诉某人\n必须在某物上贴上标签时，"\n"他们会\n事先考虑成分。"\n这里的类比可能是，\n"如果我想做一个三明治\n并说它不含麸质，"\n"我必须在\n制作三明治时考虑所有成分，"\n面包和配料，酱汁。\n"我不能只是把它放在三明治上\n然后放在你面前"\n并告诉你它不含麸质。\n"我们\n对我们所做的工作感到非常自豪。"\n"我们将其作为设计推出，\n然后是原型，"\n"最终成为其他人\n制作自己标签的工具。"\n"我们与\n微软研究院、联合国等机构的专家"\n以及全球教授合作，将\n标签和方法整合\n"到他们的工作流程\n和课程中。"\n但我们知道这只是到目前为止。\n"那是因为实际上\n很难"\n在每个数据集上获得标签。\n这归结为一个问题：\n"为什么要\n在数据集上添加标签？"\n"嗯，第一个原因\n不是火箭科学。"\n这是你必须这样做的。\n"坦率地说，这就是\n食品营养标签存在的原因。"\n"因为如果他们不把它们贴\n在盒子上，那就是非法的。"\n"然而，我们并没有真正的\n人工智能监管。"\n"我们\n对数据的使用没有太多监管。"\n现在有一些即将出现。\n"例如，欧盟人工智能法案\n本周刚刚通过。"\n"尽管没有\n关于提供训练数据的要求，但"\n"他们确实有创建\n透明度标签的规定，"\n"例如数据集营养标签、\n数据表、数据声明。"\n空间里有很多。\n我们认为这是非常好的第一步。 数据集上\n"可能有标签的第二个原因\n"\n"是它是最佳实践\n或文化规范。"\n"这里的例子可能是\n我们如何开始看到"\n"越来越多的\n餐馆的食品包装和菜单"\n"包含\n有关是否含有麸质的信息。"\n法律没有要求这样做，\n"但如果你确实这么说了，\n最好是真的。"\n"人们之所以将\n其添加到菜单"\n和食品包装中，\n"是因为人们越来越\n意识到"\n"\n这种过敏或病症的敏感性和严重性。"\n"所以我们也看到\n这个领域发生了一些变化。"\n"构建数据集的人们\n开始"\n在他们的数据集上添加营养标签、数据表。\n"使用数据的人\n开始请求信息。"\n这真是令人振奋。\n"你可能会说，“卡西亚，\n你为什么在这里？"\n"一切似乎都很顺利，\n似乎正在变得更好。”"\n在某些方面确实如此。\n"但我也想告诉你们，\n我们与数据的关系"\n正在变得越来越糟。\n"现在，过去几年人们\n"\n对收集数据集的兴趣越来越浓厚。\n公司正在抓取网络。\n"他们正在将数百万小时\n的 YouTube 视频转录成文本。"\n"据估计，\n到 2026 年，他们将耗尽互联网上的信息。"\n"他们甚至考虑购买\n出版社，"\n"以便获得\n印刷文本和书籍。"\n"那么他们为什么要收集\n这些信息呢？"\n"嗯，他们需要\n越来越多的信息"\n"来训练一种\n称为生成人工智能的新技术。"\n"我想告诉您\n这些数据集的大小。"\n"如果你看一下\n2020 年推出的模型 GPT-3，"\n"训练数据集包括\n3000 亿个单词或部分单词。"\n"现在就上下文而言，英语\n包含的单词不到一百万个。"\n仅仅三年后，DBRX 就推出了，\n它接受了 8 万亿字的训练。\n"所以三年内3000亿到8\n万亿。"\n而且数据集越来越大。\n现在，随着模型的不断推出，\n"数据集实际上\n越来越不透明。"\n"即使我们可以\n访问这些信息，但"\n"它太大了，如果\n没有任何透明工具，就很难了解其内部情况。"\n"而生成式人工智能本身\n也引起了一些担忧。"\n"您可能已经\n通过 ChatGPT 遇到过这种技术。"\n"我不需要知道\n你在互联网上做什么，"\n那是你和互联网之间的事情，\n但你可能知道，就像我一样，\n"\n使用 ChatGPT"\n和其他生成式人工智能技术创建信息\n并将其发布出来是多么容易 到网上。\n因此，我们正在考虑这样一种情况，\n"我们将遇到\n大量通过"\n"算法生成的信息，\n但我们不知道它"\n，也不知道它是否真实。\n"这增加了\n人工智能潜在风险和危害的规模。"\n抱歉，不仅如此，\n"模型本身也\n被"\n"\n美国科技公司中越来越少的私人参与者所控制。"\n"这是\n去年 2023 年推出的型号。"\n"你可以看到它们大部分是粉红色的，\n这意味着它们是工业界出来的。"\n"如果你随着时间的推移观察这一点，就会发现\n越来越多的产品来自工业界，而"\n"来自\n所有其他部门的人越来越少，"\n包括学术界和政府，这些领域的\n"技术通常\n以"\n更容易审查的方式推出 。\n因此，如果我们回到咖啡馆的类比，\n"这就像\n少数私人演员"\n拥有所有原料，\n他们在全球范围内生产所有三明治，\n并且没有太多监管。\n"因此，此时\n您可能会感到害怕，"\n并且可能会感到有点不舒服。\n"这很讽刺，因为几分钟前，\n我打算给你们买三明治，"\n而你答应了。\n"这就是为什么你不应该接受\n陌生人的食物。"\n"但如果我不是同样乐观的话，我就不会站在这里。\n"\n"那是因为我认为\n我们有"\n"监管\n和文化变革背后的动力。"\n"特别是如果我们遵守有关\n"\n"企业\n应如何处理数据的三个基本原则。"\n"第一个原则是\n收集数据的公司应该告诉我们"\n他们正在收集什么。\n"这将使我们能够提出\n这样的问题：它是否受版权保护？"\n该信息属于私人信息吗？\n你能停下来吗？\n"它还\n向科学探究开放了数据。"\n"第二个原则是，\n收集我们数据的公司应该在对这些数据采取任何行动之前告诉我们"\n"他们将用这些数据做什么\n。"\n"通过要求公司\n告诉我们他们的计划，"\n这意味着他们必须有一个计划，\n这将是一个伟大的第一步。\n"它还可能会导致\n数据捕获的最小化，"\n"因为\n"\n"如果他们不知道自己要如何处理数据，他们将无法捕获数据\n。"\n最后，原则三，\n"构建人工智能的公司\n应该告诉我们"\n他们用于训练人工智能的数据。\n"这就是\n数据集营养标签"\n"和其他透明度标签\n发挥作用的地方。"\n"您知道，在大多数情况下数据\n本身无法提供的情况下"\n，\n"标签对于我们\n能够调查成分"\n并开始寻找解决方案至关重要。\n所以我想告诉你们一个好消息，\n"那就是数据\n营养项目和其他项目"\n只是全球人工智能问责运动的一小部分\n。\n"数据集营养标签\n和其他项目只是第一步。"\n监管即将出台，\n文化规范正在发生变化，\n"特别是如果我们\n遵守这三个基本原则，"\n"即公司应该告诉我们他们\n正在收集什么，在他们做任何事情之前"\n"告诉我们他们将用它做什么\n，"\n以及 构建人工智能的公司\n"应该解释\n他们用来构建系统的数据。"\n"我们需要让\n这些组织"\n对他们正在构建的人工智能负责\n"，就像我们\n对食品行业所做的那样，询问他们"\n里面有什么以及你是如何制作的？\n"只有这样，我们才能在问题\n发生之前（"\n而不是发生之后）缓解问题。\n"在此过程中，创建\n一个"\n对每个人都更健康的集成算法互联网。\n谢谢。\n（掌声）')])])}),[],!1,null,null,null);e.default=o.exports}}]);